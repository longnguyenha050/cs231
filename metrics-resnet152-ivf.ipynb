{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10197723,"sourceType":"datasetVersion","datasetId":6242968}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ndef load_data(submission_file, ground_truth_file):\n    \"\"\"\n    Đọc file test-submission và ground-truth, xử lý NaN và chuyển thành cấu trúc phù hợp.\n    \"\"\"\n    # Đọc test-submission\n    submission = pd.read_csv(submission_file)\n    submission.columns = submission.columns.str.strip()  # Xóa khoảng trắng trong tên cột\n    \n    # Đọc ground-truth\n    ground_truth = pd.read_csv(ground_truth_file)\n    ground_truth.columns = ground_truth.columns.str.strip()  # Xóa khoảng trắng trong tên cột\n    \n    # Xử lý NaN: thay NaN trong cột 'relevant_images' bằng chuỗi rỗng\n    ground_truth['relevant_images'] = ground_truth['relevant_images'].fillna(\"\")\n    \n    # Chuyển ground-truth thành dictionary\n    ground_truth_dict = {}\n    for _, row in ground_truth.iterrows():\n        query = row['query']\n        relevant_images = set(row['relevant_images'].split())  # Chuyển chuỗi thành set\n        ground_truth_dict[query] = relevant_images\n    \n    return submission, ground_truth_dict\n\n\ndef average_precision_at_k(relevant_images, predicted_images, k):\n    \"\"\"\n    Tính Average Precision (AP) cho top-k kết quả của 1 query.\n    \"\"\"\n    if not relevant_images:\n        return 0.0  # Nếu không có ảnh liên quan, AP = 0\n    \n    predicted_images_at_k = predicted_images[:k]\n    num_relevant = 0\n    precision_sum = 0.0\n\n    for i, image in enumerate(predicted_images_at_k):\n        if image in relevant_images:\n            num_relevant += 1\n            precision_sum += num_relevant / (i + 1)\n    \n    # Average Precision\n    return precision_sum / len(relevant_images)\n\n\ndef mean_average_precision(submission, ground_truth_dict, top_k_list):\n    \"\"\"\n    Tính Mean Average Precision (mAP) cho các top-k kết quả.\n    \"\"\"\n    map_scores = {k: 0.0 for k in top_k_list}\n    num_queries = 0\n\n    for _, row in submission.iterrows():\n        query = row['id']\n        \n        # Xử lý NaN trong 'images' (thay NaN bằng chuỗi rỗng)\n        predicted_images = str(row['images']).split() if pd.notna(row['images']) else []\n\n        if query not in ground_truth_dict:\n            continue\n        \n        relevant_images = ground_truth_dict[query]\n        num_queries += 1\n\n        # Tính AP cho từng giá trị k\n        for k in top_k_list:\n            ap = average_precision_at_k(relevant_images, predicted_images, k)\n            map_scores[k] += ap\n    \n    # Chia tổng AP cho số lượng query để tính mAP\n    for k in top_k_list:\n        map_scores[k] /= num_queries\n    \n    return map_scores\n\n\n\ndef main():\n    # Đường dẫn file test-submission và ground-truth\n    submission_file = '/kaggle/input/deepfashion1/test_submission_Resnet152_IVF.csv'  # Thay bằng đường dẫn file test-submission của bạn\n    ground_truth_file = '/kaggle/input/deepfashion1/ground_truth.csv'   # Thay bằng đường dẫn file ground-truth của bạn\n    \n    # Đọc dữ liệu\n    submission, ground_truth_dict = load_data(submission_file, ground_truth_file)\n    \n    # Tính mAP cho top-1, top-5, top-10\n    top_k_list = [1, 5, 10]\n    map_scores = mean_average_precision(submission, ground_truth_dict, top_k_list)\n    \n    # In kết quả\n    for k in top_k_list:\n        print(f\"Mean Average Precision for top-{k}: {map_scores[k]:.6f}\")\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T15:08:36.901146Z","iopub.execute_input":"2024-12-14T15:08:36.901643Z","iopub.status.idle":"2024-12-14T15:08:39.395438Z","shell.execute_reply.started":"2024-12-14T15:08:36.901592Z","shell.execute_reply":"2024-12-14T15:08:39.394026Z"}},"outputs":[{"name":"stdout","text":"Mean Average Precision for top-1: 0.217288\nMean Average Precision for top-5: 0.352205\nMean Average Precision for top-10: 0.354768\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Hàm chuyển đổi chuỗi thành danh sách dựa trên khoảng trắng\ndef split_by_space(value):\n    if pd.isna(value):\n        return []\n    return value.split()\n\n\n# Hàm lấy top_k ảnh cho một ảnh query\ndef get_top_k_results(df, query_image, k):\n    submission_row = df[df['id'] == query_image]\n    if not submission_row.empty:\n        top_k_results = submission_row.iloc[0]['images'][:k]\n        return top_k_results\n    return []\n\n# Hàm tính Recall@k\ndef calculate_recall_at_k(top_k_results, query_image, total_relevant):\n    if total_relevant == 0:\n        return 0\n    relevant_images = set(ground_truth_mapping.get(query_image, []))\n    retrieved_relevant = len(relevant_images.intersection(top_k_results))\n    return retrieved_relevant / total_relevant\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T15:08:48.614888Z","iopub.execute_input":"2024-12-14T15:08:48.615217Z","iopub.status.idle":"2024-12-14T15:08:48.624311Z","shell.execute_reply.started":"2024-12-14T15:08:48.615191Z","shell.execute_reply":"2024-12-14T15:08:48.622897Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\n# Đọc dữ liệu từ file ground_truth.csv và test_submission_Resnet152_IVF.csv\nground_truth_path = '/kaggle/input/deepfashion1/ground_truth.csv'\ntest_submission_path = '/kaggle/input/deepfashion1/test_submission_Resnet152_IVF.csv'\n\nground_truth_df = pd.read_csv(ground_truth_path)\ntest_submission_df = pd.read_csv(test_submission_path)\n\n# Chuẩn hóa cột 'relevant_images' trong ground_truth_df\nground_truth_df['relevant_images'] = ground_truth_df['relevant_images'].apply(split_by_space)\n\n# Tạo từ điển ground_truth từ ground_truth.csv\nground_truth_mapping = {\n    row['query']: row['relevant_images']\n    for _, row in ground_truth_df.iterrows()\n}\n\n# Chuẩn hóa cột 'images' trong test_submission_df\ntest_submission_df['images'] = test_submission_df['images'].apply(split_by_space)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T15:08:52.086948Z","iopub.execute_input":"2024-12-14T15:08:52.087368Z","iopub.status.idle":"2024-12-14T15:08:52.702927Z","shell.execute_reply.started":"2024-12-14T15:08:52.087329Z","shell.execute_reply":"2024-12-14T15:08:52.701889Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Biến lưu tổng Recall@k và số lượng query\nnum_queries = 0\ntotal_recall_at_k_1 = 0\ntotal_recall_at_k_5 = 0\ntotal_recall_at_k_10 = 0\ntotal_recall_at_k_50 = 0\n\n# Duyệt qua từng ảnh query trong ground_truth_df\nfor query_image in ground_truth_df['query']:\n    # Kiểm tra nếu query_image có trong cột 'id' của test_submission_df\n    if query_image not in test_submission_df['id'].values:\n        continue\n\n    total_relevant = len(ground_truth_mapping.get(query_image, []))\n\n    # Lấy top_k_results cho từng giá trị k\n    top_k_results_1 = get_top_k_results(test_submission_df, query_image, 1)\n    top_k_results_5 = get_top_k_results(test_submission_df, query_image, 5)\n    top_k_results_10 = get_top_k_results(test_submission_df, query_image, 10)\n    top_k_results_50 = get_top_k_results(test_submission_df, query_image, 50)\n\n    # Tính Recall@k\n    recall_at_k_1 = calculate_recall_at_k(top_k_results_1, query_image, total_relevant)\n    recall_at_k_5 = calculate_recall_at_k(top_k_results_5, query_image, total_relevant)\n    recall_at_k_10 = calculate_recall_at_k(top_k_results_10, query_image, total_relevant)\n    recall_at_k_50 = calculate_recall_at_k(top_k_results_50, query_image, total_relevant)\n\n    # Cộng dồn Recall@k\n    total_recall_at_k_1 += recall_at_k_1\n    total_recall_at_k_5 += recall_at_k_5\n    total_recall_at_k_10 += recall_at_k_10\n    total_recall_at_k_50 += recall_at_k_50\n\n    num_queries += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T15:08:55.502492Z","iopub.execute_input":"2024-12-14T15:08:55.503292Z","iopub.status.idle":"2024-12-14T15:08:55.826072Z","shell.execute_reply.started":"2024-12-14T15:08:55.503262Z","shell.execute_reply":"2024-12-14T15:08:55.824231Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Tính Recall@k trung bình\nif num_queries > 0:\n    average_recall_at_k_1 = total_recall_at_k_1 / num_queries\n    average_recall_at_k_5 = total_recall_at_k_5 / num_queries\n    average_recall_at_k_10 = total_recall_at_k_10 / num_queries\n    average_recall_at_k_50 = total_recall_at_k_50 / num_queries\n\n    print(f\"Recall@1 trung bình: {average_recall_at_k_1:.4f}\")\n    print(f\"Recall@5 trung bình: {average_recall_at_k_5:.4f}\")\n    print(f\"Recall@10 trung bình: {average_recall_at_k_10:.4f}\")\n    print(f\"Recall@50 trung bình: {average_recall_at_k_50:.4f}\")\nelse:\n    print(\"Không có ảnh query có ảnh liên quan để tính Recall.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T15:08:59.781838Z","iopub.execute_input":"2024-12-14T15:08:59.782293Z","iopub.status.idle":"2024-12-14T15:08:59.791148Z","shell.execute_reply.started":"2024-12-14T15:08:59.782263Z","shell.execute_reply":"2024-12-14T15:08:59.789640Z"}},"outputs":[{"name":"stdout","text":"Recall@1 trung bình: 0.2173\nRecall@5 trung bình: 0.3687\nRecall@10 trung bình: 0.3763\nRecall@50 trung bình: 0.3763\n","output_type":"stream"}],"execution_count":5}]}